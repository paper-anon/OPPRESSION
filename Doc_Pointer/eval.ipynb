{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_folder = \"results\"\n",
    "texts_folder = \"../texts\"\n",
    "temp_folder = \"temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_targets = [\"wikipedia-cities\", \"wikipedia-sports\", \"wikipedia-science\", \"wikipedia-history\"]\n",
    "book_targets = [\"book-dracula\"]\n",
    "twitter_targets = [\"twitter-ellenshow\"]\n",
    "news_target = [\"newspapers-bbc\", \"newspapers-reuters\"]\n",
    "\n",
    "targets = wiki_targets + book_targets + twitter_targets + news_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_target = open(f\"{texts_folder}/to_submit/sanitized/book-dracula\",\"r\").read().title().split(\" \")[319:]\n",
    "news_target_bbc = open(f\"{texts_folder}/to_submit/sanitized/newspapers-bbc\",\"r\").read().title().split(\" \")\n",
    "news_target_reuters = open(f\"{texts_folder}/to_submit/sanitized/newspapers-reuters\",\"r\").read().title().split(\" \")\n",
    "wiki_target_cities = open(f\"{texts_folder}/to_submit/sanitized/wikipedia-cities\",\"r\").read().title().split(\" \")\n",
    "wiki_target_history = open(f\"{texts_folder}/to_submit/sanitized/wikipedia-history\",\"r\").read().title().split(\" \")\n",
    "wiki_target_science = open(f\"{texts_folder}/to_submit/sanitized/wikipedia-science\",\"r\").read().title().split(\" \")\n",
    "wiki_target_sports = open(f\"{texts_folder}/to_submit/sanitized/wikipedia-sports\",\"r\").read().title().split(\" \")\n",
    "twitter_target =  open(f\"{texts_folder}/to_submit/sanitized/twitter-ellenshow\",\"r\").read().title().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_trees = [\"wikipedia_cities\", \"wikipedia_sports\", \"wikipedia_scientists\", \"wikipedia_history\",\"wikipedia_joined\"]\n",
    "book_trees = [\"book_grimm\", \"book_holmes\", \"book_joined\", \"book_pride\", \"book_joined\"]\n",
    "twitter_trees = [\"twitter_defcon\", \"twitter_gates\", \"twitter_huckabee\", \"twitter_musk\", \"twitter_obama\", \"twitter_rice\", \"twitter_joined\"]\n",
    "news_trees = [\"newspaper_bbc\", \"newspaper_reuters\", \"newspaper_joined\"]\n",
    "\n",
    "trees = wiki_trees+book_trees+twitter_trees+news_trees+[\"supergroup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [2,3,5,10,15]\n",
    "\n",
    "lengths = [100,200,300,400,500,1000]\n",
    "\n",
    "for length in lengths:\n",
    "    with open(f\"{temp_folder}/book-dracula_{length}.txt\",\"w\") as f:\n",
    "            for w in book_target[:length]:\n",
    "                f.write(f\"{w} \")\n",
    "    with open(f\"{temp_folder}/newspapers-bbc_{length}.txt\",\"w\") as f:\n",
    "            for w in news_target_bbc[:length]:\n",
    "                f.write(f\"{w} \")\n",
    "    with open(f\"{temp_folder}/newspapers-reuters_{length}.txt\",\"w\") as f:\n",
    "            for w in news_target_reuters[:length]:\n",
    "                f.write(f\"{w} \")\n",
    "    with open(f\"{temp_folder}/wikipedia-cities_{length}.txt\",\"w\") as f:\n",
    "            for w in wiki_target_cities[:length]:\n",
    "                f.write(f\"{w} \")\n",
    "    with open(f\"{temp_folder}/wikipedia-history_{length}.txt\",\"w\") as f:\n",
    "            for w in wiki_target_history[:length]:\n",
    "                f.write(f\"{w} \")\n",
    "    with open(f\"{temp_folder}/wikipedia-science_{length}.txt\",\"w\") as f:\n",
    "            for w in wiki_target_science[:length]:\n",
    "                f.write(f\"{w} \")\n",
    "    with open(f\"{temp_folder}/wikipedia-sports_{length}.txt\",\"w\") as f:\n",
    "            for w in wiki_target_sports[:length]:\n",
    "                f.write(f\"{w} \")\n",
    "    with open(f\"{temp_folder}/twitter-ellenshow_{length}.txt\",\"w\") as f:\n",
    "        for w in twitter_target[:length]:\n",
    "            f.write(f\"{w} \")\n",
    "\n",
    "with open(f\"{temp_folder}/book-dracula_long.txt\",\"w\") as f:\n",
    "        for w in book_target:\n",
    "            f.write(f\"{w} \")\n",
    "with open(f\"{temp_folder}/newspapers-bbc_long.txt\",\"w\") as f:\n",
    "        for w in news_target_bbc:\n",
    "            f.write(f\"{w} \")\n",
    "with open(f\"{temp_folder}/newspapers-reuters_long.txt\",\"w\") as f:\n",
    "        for w in news_target_reuters:\n",
    "            f.write(f\"{w} \")\n",
    "with open(f\"{temp_folder}/wikipedia-cities_long.txt\",\"w\") as f:\n",
    "        for w in wiki_target_cities:\n",
    "            f.write(f\"{w} \")\n",
    "with open(f\"{temp_folder}/wikipedia-history_long.txt\",\"w\") as f:\n",
    "        for w in wiki_target_history:\n",
    "            f.write(f\"{w} \")\n",
    "with open(f\"{temp_folder}/wikipedia-science_long.txt\",\"w\") as f:\n",
    "        for w in wiki_target_science:\n",
    "            f.write(f\"{w} \")\n",
    "with open(f\"{temp_folder}/wikipedia-sports_long.txt\",\"w\") as f:\n",
    "        for w in wiki_target_sports:\n",
    "            f.write(f\"{w} \")\n",
    "with open(f\"{temp_folder}/twitter-ellenshow_long.txt\",\"w\") as f:\n",
    "    for w in twitter_target:\n",
    "        f.write(f\"{w} \")\n",
    "\n",
    "os.system(f\"gzip -fk -9 -n {temp_folder}/*.txt\")\n",
    "for depth in depths:\n",
    "    for length in lengths:\n",
    "        os.system(f\"gzip -fk -9 -n {res_folder}/{depth}/*.opp_{length}.rand_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in depths:\n",
    "    df = pd.DataFrame({\"tree\":[],\"target\":[],\"OppRatio\":[],\"GzRatio\":[],\"OppGzRatio\":[]})\n",
    "    for tree in trees:\n",
    "        for target in targets:\n",
    "            opp = {}\n",
    "            opp_GZ = {}\n",
    "            my_GZ = {}\n",
    "            for length in lengths:\n",
    "                opp_size = Path(f\"{res_folder}/{depth}/{target}_{tree}.opp_{length}.rand_bin\").stat().st_size\n",
    "                opp_GZ_size = Path(f\"{res_folder}/{depth}/{target}_{tree}.opp_{length}.rand_bin.gz\").stat().st_size\n",
    "                GZ_size = Path(f\"{temp_folder}/{target}_{length}.txt.gz\").stat().st_size\n",
    "                txt_size = Path(f\"{temp_folder}/{target}_{length}.txt\").stat().st_size\n",
    "                opp[str(length)] = opp_size/txt_size\n",
    "                opp_GZ[str(length)] = opp_GZ_size/txt_size\n",
    "                my_GZ[str(length)] = GZ_size/txt_size\n",
    "            df = pd.concat([df,pd.DataFrame({\"tree\":[tree],\"target\":[target],\"OppRatio\":[opp],\"GzRatio\":[my_GZ],\"OppGzRatio\":[opp_GZ]})])\n",
    "    df.to_pickle(f\"{res_folder}/Crossref_{depth}.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in depths:\n",
    "    df = pd.DataFrame({\"tree\":[],\"target\":[],\"OppRatio\":[],\"GzRatio\":[],\"OppGzRatio\":[]})\n",
    "    for tree in trees:\n",
    "        for target in targets:\n",
    "            opp = {}\n",
    "            opp_GZ = {}\n",
    "            my_GZ = {}\n",
    "            for length in [1000]:\n",
    "                opp_size = Path(f\"{res_folder}/{depth}/{target}_{tree}.opp_{length}.rand_bin\").stat().st_size\n",
    "                opp_GZ_size = Path(f\"{res_folder}/{depth}/{target}_{tree}.opp_{length}.rand_bin.gz\").stat().st_size\n",
    "                GZ_size = Path(f\"{temp_folder}/{target}_{length}.txt.gz\").stat().st_size\n",
    "                txt_size = Path(f\"{temp_folder}/{target}_{length}.txt\").stat().st_size\n",
    "                opp[str(length)] = opp_size/txt_size\n",
    "                opp_GZ[str(length)] = opp_GZ_size/txt_size\n",
    "                my_GZ[str(length)] = GZ_size/txt_size\n",
    "            df = pd.concat([df,pd.DataFrame({\"tree\":[tree],\"target\":[target],\"OppRatio\":[opp],\"GzRatio\":[my_GZ],\"OppGzRatio\":[opp_GZ]})])\n",
    "    df.to_pickle(f\"{res_folder}/Crossref_{depth}_long.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crossref_2 = pd.read_pickle(f\"{res_folder}/Crossref_2.p\")\n",
    "df_crossref_3 = pd.read_pickle(f\"{res_folder}/Crossref_3.p\")\n",
    "df_crossref_5 = pd.read_pickle(f\"{res_folder}/Crossref_5.p\")\n",
    "df_crossref_10 = pd.read_pickle(f\"{res_folder}/Crossref_10.p\")\n",
    "df_crossref_15 = pd.read_pickle(f\"{res_folder}/Crossref_15.p\")\n",
    "\n",
    "\n",
    "df_crossref_2_long = pd.read_pickle(f\"{res_folder}/Crossref_2_long.p\")\n",
    "df_crossref_3_long = pd.read_pickle(f\"{res_folder}/Crossref_3_long.p\")\n",
    "df_crossref_5_long = pd.read_pickle(f\"{res_folder}/Crossref_5_long.p\")\n",
    "df_crossref_10_long = pd.read_pickle(f\"{res_folder}/Crossref_10_long.p\")\n",
    "df_crossref_15_long = pd.read_pickle(f\"{res_folder}/Crossref_15_long.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_crossref_2.tree.unique())\n",
    "print(df_crossref_2.target.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_trees = [\"book_joined\",\"newspaper_joined\",\"wikipedia_joined\",\"twitter_joined\",\"supergroup\"]\n",
    "\n",
    "selection_targets = ['wikipedia-cities', 'wikipedia-sports', 'wikipedia-science', 'wikipedia-history', 'book-dracula', 'twitter-ellenshow', 'newspapers-bbc', 'newspapers-reuters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crossref_2 = df_crossref_2[df_crossref_2[\"tree\"].isin(selection_trees)]\n",
    "df_crossref_3 = df_crossref_3[df_crossref_3[\"tree\"].isin(selection_trees)]\n",
    "df_crossref_5 = df_crossref_5[df_crossref_5[\"tree\"].isin(selection_trees)]\n",
    "df_crossref_10 = df_crossref_10[df_crossref_10[\"tree\"].isin(selection_trees)]\n",
    "df_crossref_15 = df_crossref_15[df_crossref_15[\"tree\"].isin(selection_trees)]\n",
    "\n",
    "df_crossref_2 = df_crossref_2[df_crossref_2[\"target\"].isin(selection_targets)]\n",
    "df_crossref_3 = df_crossref_3[df_crossref_3[\"target\"].isin(selection_targets)]\n",
    "df_crossref_5 = df_crossref_5[df_crossref_5[\"target\"].isin(selection_targets)]\n",
    "df_crossref_10 = df_crossref_10[df_crossref_10[\"target\"].isin(selection_targets)]\n",
    "df_crossref_15 = df_crossref_15[df_crossref_15[\"target\"].isin(selection_targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_id(tree):\n",
    "    return np.where(df_crossref_2[\"tree\"].unique() == tree)[0][0]\n",
    "\n",
    "def target_to_id(target):\n",
    "    return np.where(df_crossref_2[\"target\"].unique() == target)[0][0]\n",
    "\n",
    "def translator(input_name):\n",
    "    if input_name == \"book-dracula\":\n",
    "        return \"Books\"\n",
    "    if input_name == \"newspapers-bbc\":\n",
    "        return \"BBC\"\n",
    "    if input_name == \"newspapers-reuters\":\n",
    "        return \"Reuters\"\n",
    "    if input_name == \"wikipedia-history\":\n",
    "        return \"Wiki Hist.\"\n",
    "    if input_name == \"wikipedia-cities\":\n",
    "        return \"Wiki Cities\"\n",
    "    if input_name == \"wikipedia-science\":\n",
    "        return \"Wiki Sci.\"\n",
    "    if input_name == \"wikipedia-sports\":\n",
    "        return \"Wiki Sport\"\n",
    "    if input_name == \"twitter-ellenshow\":\n",
    "        return \"Twitter\"\n",
    "    if input_name == \"book_joined\":\n",
    "        return \"Books\"\n",
    "    if input_name == \"newspaper_joined\":\n",
    "        return \"News\"\n",
    "    if input_name == \"wikipedia_joined\":\n",
    "        return \"Wiki\"\n",
    "    if input_name == \"twitter_joined\":\n",
    "        return \"Twitter\"\n",
    "    if input_name == \"supergroup\":\n",
    "        return \"Combi\"\n",
    "    return input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorter(x):\n",
    "    print(x)\n",
    "    if x == \"book-dracula\":\n",
    "        return 0\n",
    "    if x == \"newspapers-bbc\":\n",
    "        return 1\n",
    "    if x == \"newspapers-reuters\":\n",
    "        return 2\n",
    "    if x == \"wikipedia-history\":\n",
    "        return 3\n",
    "    if x == \"wikipedia-cities\":\n",
    "        return 4\n",
    "    if x == \"wikipedia-science\":\n",
    "        return 5\n",
    "    if x == \"wikipedia-sports\":\n",
    "        return 6\n",
    "    if x == \"twitter-ellenshow\":\n",
    "        return 7\n",
    "    if x == \"book_joined\":\n",
    "        return 8\n",
    "    if x == \"newspaper_joined\":\n",
    "        return 9\n",
    "    if x == \"wikipedia_joined\":\n",
    "        return 10\n",
    "    if x == \"twitter_joined\":\n",
    "        return 11\n",
    "    if x == \"supergroup\":\n",
    "        return 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dict = {'Books': 0, 'BBC': 1, 'Reuters': 2, \"Wiki Hist.\": 3,\n",
    "               \"Wiki Cities\":4, \"Wiki Sci.\":5, \"Wiki Sport\":6, \"Twitter\":7,\n",
    "               \"Books\":8, \"News\":9, \"Wiki\":10, \"Twitter\":11,\n",
    "               \"Combi\": 12}\n",
    "\n",
    "df_crossref_2[\"tree\"] = df_crossref_2[\"tree\"].apply(translator)\n",
    "df_crossref_3[\"tree\"] = df_crossref_3[\"tree\"].apply(translator)\n",
    "df_crossref_5[\"tree\"] = df_crossref_5[\"tree\"].apply(translator)\n",
    "df_crossref_10[\"tree\"] = df_crossref_10[\"tree\"].apply(translator)\n",
    "df_crossref_15[\"tree\"] = df_crossref_15[\"tree\"].apply(translator)\n",
    "\n",
    "df_crossref_2[\"target\"] = df_crossref_2[\"target\"].apply(translator)\n",
    "df_crossref_3[\"target\"] = df_crossref_3[\"target\"].apply(translator)\n",
    "df_crossref_5[\"target\"] = df_crossref_5[\"target\"].apply(translator)\n",
    "df_crossref_10[\"target\"] = df_crossref_10[\"target\"].apply(translator)\n",
    "df_crossref_15[\"target\"] = df_crossref_15[\"target\"].apply(translator)\n",
    "\n",
    "df_crossref_2 = df_crossref_2.sort_values(by=[\"tree\",\"target\"],key=lambda x: x.map(custom_dict))\n",
    "df_crossref_3 = df_crossref_3.sort_values([\"tree\",\"target\"],key=lambda x: x.map(custom_dict))\n",
    "df_crossref_5 = df_crossref_5.sort_values([\"tree\",\"target\"],key=lambda x: x.map(custom_dict))\n",
    "df_crossref_10 = df_crossref_10.sort_values([\"tree\",\"target\"],key=lambda x: x.map(custom_dict))\n",
    "df_crossref_15 = df_crossref_15.sort_values([\"tree\",\"target\"],key=lambda x: x.map(custom_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = df_crossref_2[\"target\"].unique().size\n",
    "height = df_crossref_2[\"tree\"].unique().size\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['axes.grid.axis'] = \"y\"\n",
    "\n",
    "pal1 = sns.color_palette(\"Blues\", n_colors=5)\n",
    "pal2 = sns.color_palette(\"Greens\", n_colors=5)\n",
    "\n",
    "# Make all colors the same\n",
    "#pal1 = [pal1[4]] * 5\n",
    "#pal2 = [pal2[4]] * 5\n",
    "\n",
    "linewidth = 1.0\n",
    "\n",
    "#linestyles = [\"dotted\", \"dashed\", \"dashdot\", (0, (3, 5, 1, 5, 1, 5)), \"solid\"]\n",
    "linestyles = [\"solid\"] * 5\n",
    "\n",
    "fig, ax =plt.subplots(height,width,figsize=(10, 5))\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i,line in df_crossref_2.iterrows():\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal1[0],linestyle=linestyles[0],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppGzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal2[0],linestyle=linestyles[0],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"GzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=\"red\")\n",
    "\n",
    "\n",
    "for i,line in df_crossref_3.iterrows():\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal1[1],linestyle=linestyles[1],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppGzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal2[1],linestyle=linestyles[1],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"GzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=\"red\")\n",
    "\n",
    "\n",
    "for i,line in df_crossref_5.iterrows():\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal1[2],linestyle=linestyles[2],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppGzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal2[2],linestyle=linestyles[2],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"GzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=\"red\")\n",
    "\n",
    "\n",
    "for i,line in df_crossref_10.iterrows():\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal1[3],linestyle=linestyles[3],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppGzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal2[3],linestyle=linestyles[3],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"GzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=\"red\")\n",
    "\n",
    "\n",
    "for i,line in df_crossref_15.iterrows():\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal1[4],linestyle=linestyles[4],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"OppGzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=pal2[4],linestyle=linestyles[4],linewidth=linewidth)\n",
    "\n",
    "    lists = sorted([(int(x),y)for (x,y) in line[\"GzRatio\"].items()])\n",
    "    x, y = zip(*lists)\n",
    "    ax[tree_to_id(line[\"tree\"]), target_to_id(line[\"target\"])].plot(x,y,c=\"red\")\n",
    "\n",
    "\n",
    "# Set \"big\" labes for ros and cols of plots\n",
    "pad = 5\n",
    "\n",
    "plt.setp(ax,xlabel=None, ylabel=None)\n",
    "for a in ax[:-1,:].flat:\n",
    "    a.set_xticklabels([])\n",
    "    pass\n",
    "for a in ax[:,1:].flat:\n",
    "    a.set_yticklabels([])\n",
    "    pass\n",
    "\n",
    "for a, col in zip(ax[0], df_crossref_2[\"target\"].unique()):\n",
    "    a.annotate(translator(col), xy=(0.5, 1), xytext=(0, pad),\n",
    "                xycoords='axes fraction', textcoords='offset points',\n",
    "                size='large', ha='center', va='baseline')\n",
    "\n",
    "\n",
    "for a, row in zip(ax[:,0], df_crossref_2[\"tree\"].unique()):\n",
    "    a.annotate(translator(row), xy=(0, 0.5), xytext=(-a.yaxis.labelpad - pad, 0),\n",
    "                xycoords=a.yaxis.label, textcoords='offset points',\n",
    "                size='large', ha='right', va='center')\n",
    "\n",
    "\n",
    "for idx, a in enumerate(ax[-1]):\n",
    "    if idx == 3:\n",
    "        a.set_xlabel(\"Text Length (Words)\")\n",
    "    \n",
    "\n",
    "for idx, a in enumerate(ax[:,0]):\n",
    "    if idx == 2:\n",
    "        a.set_ylabel(\"Ratio\\n(lower is better)\")\n",
    "    else:\n",
    "        a.set_ylabel(\" \\n\")\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "\n",
    "fig.text(0.5, 0.95, 'Target Message', ha='center',fontdict={\"size\":15})\n",
    "fig.text(-0.04, 0.5, 'Encoding Tree', va='center', rotation='vertical',fontdict={\"size\":15})\n",
    "plt.setp(ax,ylim=(0.15,0.75))\n",
    "opp_patch = mpatches.Patch(color=pal1[4], label='Opp')\n",
    "opp_gz_patch = mpatches.Patch(color=pal2[4], label='Opp+GZ')\n",
    "gz_patch = mpatches.Patch(color=\"red\", label='GZip')\n",
    "\n",
    "fig.legend(handles=[opp_patch,opp_gz_patch,gz_patch],loc=3)\n",
    "\n",
    "plt.savefig(\"Encoding_doc_point.eps\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crossref_2_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = \"1000\"\n",
    "opp = [i[length] for i in df_crossref_2_long[\"OppRatio\"]]\n",
    "opp.extend([i[length] for i in df_crossref_3_long[\"OppRatio\"]])\n",
    "opp.extend([i[length] for i in df_crossref_5_long[\"OppRatio\"]])\n",
    "opp.extend([i[length] for i in df_crossref_10_long[\"OppRatio\"]])\n",
    "opp.extend([i[length] for i in df_crossref_15_long[\"OppRatio\"]])\n",
    "\n",
    "opp_gz = [i[length] for i in df_crossref_2_long[\"OppGzRatio\"]]\n",
    "opp_gz.extend([i[length] for i in df_crossref_3_long[\"OppGzRatio\"]])\n",
    "opp_gz.extend([i[length] for i in df_crossref_5_long[\"OppGzRatio\"]])\n",
    "opp_gz.extend([i[length] for i in df_crossref_10_long[\"OppGzRatio\"]])\n",
    "opp_gz.extend([i[length] for i in df_crossref_15_long[\"OppGzRatio\"]])\n",
    "\n",
    "gz = [i[length] for i in df_crossref_2_long[\"GzRatio\"]]\n",
    "gz.extend([i[length] for i in df_crossref_3_long[\"GzRatio\"]])\n",
    "gz.extend([i[length] for i in df_crossref_5_long[\"GzRatio\"]])\n",
    "gz.extend([i[length] for i in df_crossref_10_long[\"GzRatio\"]])\n",
    "gz.extend([i[length] for i in df_crossref_15_long[\"GzRatio\"]])\n",
    "\n",
    "box_df = pd.DataFrame({\"Opp\":opp,\"OppGz\":opp_gz,\"Gz\":gz})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_df.boxplot()\n",
    "plt.ylabel(\"Compression Ratio\\n(lower is better)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opp_2 = [i[length] for i in df_crossref_2_long[\"OppRatio\"]]\n",
    "opp_15 = [i[length] for i in df_crossref_15_long[\"OppRatio\"]]\n",
    "\n",
    "opp_gz_2 = [i[length] for i in df_crossref_2_long[\"OppGzRatio\"]]\n",
    "opp_gz_15 = [i[length] for i in df_crossref_15_long[\"OppGzRatio\"]]\n",
    "\n",
    "gz_2 = [i[length] for i in df_crossref_2_long[\"GzRatio\"]]\n",
    "gz_15 = [i[length] for i in df_crossref_15_long[\"GzRatio\"]]\n",
    "\n",
    "df = []\n",
    "for i in opp_2:\n",
    "    df.append({\"Algo\":\"Opp\",\"Ratio\":i,\"Depth\":2})\n",
    "for i in opp_15:\n",
    "    df.append({\"Algo\":\"Opp\",\"Ratio\":i,\"Depth\":15})\n",
    "\n",
    "for i in opp_gz_2:\n",
    "    df.append({\"Algo\":\"OppGZ\",\"Ratio\":i,\"Depth\":2})\n",
    "for i in opp_gz_15:\n",
    "    df.append({\"Algo\":\"OppGZ\",\"Ratio\":i,\"Depth\":15})\n",
    "\n",
    "for i in gz_2:\n",
    "    df.append({\"Algo\":\"GZ\",\"Ratio\":i,\"Depth\":2})\n",
    "for i in gz_15:\n",
    "    df.append({\"Algo\":\"GZ\",\"Ratio\":i,\"Depth\":15})\n",
    "\n",
    "df_box_sep = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.boxplot(df_box_sep,x=\"Algo\",y=\"Ratio\",hue=\"Depth\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylim(0.2,1.0)\n",
    "plt.savefig(\"Box_doc_point.eps\",bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPPRESSION",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41e1035467d31ba65524366443ff7d2edd6421e5a76f8b69fbd0d60bb69aa33c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
